{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carcrash Severity Prediction\n",
    "\n",
    "Downloading the datasets:\n",
    "\n",
    "Please run `wget https://data.wprdc.org/dataset/3130f583-9499-472b-bb5a-f63a6ff6059a/resource/ec578660-2d3f-489d-9ba1-af0ebfc3b140/download/all-crashes-2004-2018.csv.zip`\n",
    "or visit this link to get the Allegheny County crash data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import ckanapi\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "site = \"https://data.wprdc.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_resource_data(site,resource_id,count=50):\n",
    "    # Use the datastore_search API endpoint to get <count> records from\n",
    "    # a CKAN resource.\n",
    "    ckan = ckanapi.RemoteCKAN(site)\n",
    "    response = ckan.action.datastore_search(id=resource_id, limit=count)\n",
    "\n",
    "    # A typical response is a dictionary like this\n",
    "    #{u'_links': {u'next': u'/api/action/datastore_search?offset=3',\n",
    "    #             u'start': u'/api/action/datastore_search'},\n",
    "    # u'fields': [{u'id': u'_id', u'type': u'int4'},\n",
    "    #             {u'id': u'pin', u'type': u'text'},\n",
    "    #             {u'id': u'number', u'type': u'int4'},\n",
    "    #             {u'id': u'total_amount', u'type': u'float8'}],\n",
    "    # u'limit': 3,\n",
    "    # u'records': [{u'_id': 1,\n",
    "    #               u'number': 11,\n",
    "    #               u'pin': u'0001B00010000000',\n",
    "    #               u'total_amount': 13585.47},\n",
    "    #              {u'_id': 2,\n",
    "    #               u'number': 2,\n",
    "    #               u'pin': u'0001C00058000000',\n",
    "    #               u'total_amount': 7827.64},\n",
    "    #              {u'_id': 3,\n",
    "    #               u'number': 1,\n",
    "    #               u'pin': u'0001C01661006700',\n",
    "    #               u'total_amount': 3233.59}],\n",
    "    # u'resource_id': u'd1e80180-5b2e-4dab-8ec3-be621628649e',\n",
    "    # u'total': 88232}\n",
    "    data = response['records']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "crash_data_2017 = get_resource_data(site,resource_id=\"bf8b3c7e-8d60-40df-9134-21606a451c1a\",count=999999999) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "   UNBELTED  WORK_ZONE URBAN_RURAL  DRIVER_20YR  MC_DRINKING_DRIVER  \\\n0         0          0           3            0                   0   \n1         0          0           3            0                   0   \n2         0          0           3            0                   0   \n3         0          0           3            0                   0   \n4         0          0           3            0                   0   \n\n   CELL_PHONE  PROPERTY_DAMAGE_ONLY ACCESS_CTRL  HIT_GDRAIL LOCATION_TYPE  \\\n0           0                     0        None           0            00   \n1           0                     1        None           0            00   \n2           0                     0        None           0            00   \n3           0                     1        None           0            00   \n4           0                     0        None           0            00   \n\n   ...  CROSS_MEDIAN  WZ_LN_CLOSURE  LOCAL_ROAD  DRUG_RELATED  PEDESTRIAN  \\\n0  ...             0           None           0             0           0   \n1  ...             0           None           1             0           0   \n2  ...             0           None           0             0           0   \n3  ...             0           None           1             0           0   \n4  ...             0           None           1             0           0   \n\n   MODERATE_INJURY TAILGATING  ROAD_CONDITION      LATITUDE _id  \n0                0          0               1  40 28:01.602   1  \n1                0          0               1  40 26:56.157   2  \n2                0          0               1  40 26:54.669   3  \n3                0          0               1  40 25:30.597   4  \n4                0          0               0  40 27:31.670   5  \n\n[5 rows x 191 columns]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "len(crash_data_2017)\n",
    "df = pd.DataFrame(crash_data_2017)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add a graph/animation to show the car crash data\n",
    "maybe the geospatial data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "    TIME_OF_DAY ILLUMINATION WEATHER ROAD_CONDITION INTERSECT_TYPE  \\\n29           11            1       1              5              0   \n48           13            1       4              2              0   \n52           10            1       2              2              0   \n53           15            1       1              2              0   \n54           16            1       1              3              0   \n59           13            1       2              2              0   \n61           11            1       4              5              0   \n67           21            2       4              4              2   \n69            7            1       4              5              0   \n70           10            1       4              3              0   \n\n   SCH_BUS_IND  PERSON_COUNT  AUTOMOBILE_COUNT  MOTORCYCLE_COUNT  \\\n29           0             2                 2                 0   \n48           0             3                 2                 0   \n52           0             4                 2                 0   \n53           0             3                 2                 0   \n54           0             1                 1                 0   \n59           0             2                 2                 0   \n61           0             3                 1                 0   \n67           0             1                 1                 0   \n69           0             2                 2                 0   \n70           0             2                 1                 0   \n\n    HEAVY_TRUCK_COUNT  FATAL_COUNT  INJURY_COUNT  MAX_SEVERITY_LEVEL  \\\n29                  0            0             0                   0   \n48                  0            0             0                   0   \n52                  0            0             0                   0   \n53                  0            0             2                   4   \n54                  0            0             1                   4   \n59                  0            0             1                   4   \n61                  0            0             0                   0   \n67                  0            0             0                   0   \n69                  0            0             2                   3   \n70                  0            0             0                   0   \n\n   LANE_CLOSED HAZARDOUS_TRUCK  MAJOR_INJURY  SPEED_LIMIT  \n29           0               0             0           40  \n48           1               0             0           35  \n52           0               0             0           40  \n53           2               0             0           25  \n54           2               0             0           45  \n59           2               0             0           40  \n61           2               0             0           35  \n67           0               0             0           45  \n69           1               0             0           35  \n70           0               0             0           35  \n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 43610 entries, 1 to 180963\nData columns (total 12 columns):\nROAD_CONDITION       43610 non-null object\nINTERSECT_TYPE       43610 non-null object\nLANE_CLOSED          43610 non-null object\nTIME_OF_DAY          43610 non-null int64\nSPEED_LIMIT          43610 non-null int64\nILLUMINATION         43610 non-null object\nMOTORCYCLE_COUNT     43610 non-null int64\nHEAVY_TRUCK_COUNT    43610 non-null int64\nHAZARDOUS_TRUCK      43610 non-null object\nAUTOMOBILE_COUNT     43610 non-null int64\nSCH_BUS_IND          43610 non-null object\nWEATHER              43610 non-null object\ndtypes: int64(5), object(7)\nmemory usage: 4.3+ MB\nNone\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 43610 entries, 1 to 180963\nData columns (total 5 columns):\nPERSON_COUNT          43610 non-null int64\nFATAL_COUNT           43610 non-null int64\nINJURY_COUNT          43610 non-null int64\nMAX_SEVERITY_LEVEL    43610 non-null int64\nMAJOR_INJURY          43610 non-null int64\ndtypes: int64(5)\nmemory usage: 2.0 MB\nNone\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "#clean sch_bus_ind y/n to integer 0,1\n",
    "\n",
    "def type_boolean(c):\n",
    "    if c == \"Y\": return 1\n",
    "    elif c == \"N\": return 0\n",
    "    # elif c == \"nan\": return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    # raise ValueError(c)\n",
    "\n",
    "def ROAD_CONDITION(c): # 8 is other 9 is unknown, 1,7->2, 3->4, 4->3, 5,6->5, 2,8,9->nan\n",
    "    if c == 1 or c == 7:\n",
    "        return 2\n",
    "    elif c == 3:\n",
    "        return 4\n",
    "    elif c == 4:\n",
    "        return 3\n",
    "    elif c == 5 or c == 6:\n",
    "        return 5\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def INTERSECT_TYPE(c): # 10 is other 99 is unkonw\n",
    "    if c <= 9:\n",
    "        return c\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def ILLUMINATION(c):\n",
    "    if c <= 6:\n",
    "        return c\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def WEATHER(c):\n",
    "    if c <= 7:\n",
    "        return c\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def TIME(c): # extract only the hour\n",
    "    if c <= 2500:\n",
    "        return c // 100\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "if not Path('all-crashes-2004-2018.csv.zip').exists():\n",
    "    wget.download(\"https://data.wprdc.org/dataset/3130f583-9499-472b-bb5a-f63a6ff6059a/resource/ec578660-2d3f-489d-9ba1-af0ebfc3b140/download/all-crashes-2004-2018.csv.zip\")\n",
    "# zf = zipfile.ZipFile('all-crashes-2004-2018.csv.zip') \n",
    "df_io = pd.read_csv('all-crashes-2004-2018.csv.zip')\n",
    "# print(df.head())\n",
    "# print(list(df))\n",
    "# static_columns = \"ROAD_CONDITION,INTERSECT_TYPE,URBAN_RURAL,DISTRICT,STATE_ROAD,LOCAL_ROAD,SNOW_SLUSH_ROAD,LANE_CLOSED,TIME_OF_DAY,SPEED_LIMIT\"\n",
    "# dynamic_columns = \"ILLUMINATION,MOTORCYCLE_COUNT,HEAVY_TRUCK_COUNT,WEATHER,HAZARDOUS_TRUCK,SCH_BUS_IND,AUTOMOBILE_COUNT\"\n",
    "# output_columns = \"PERSON_COUNT,FATAL_COUNT,INJURY_COUNT,MAX_SEVERITY_LEVEL,MAJOR_INJURY\"\n",
    "# df_io = df[(static_columns+\",\"+dynamic_columns+\",\"+output_columns).split(',')]\n",
    "# print(df_io.head())\n",
    "# print(df_io.dtypes)\n",
    "# print(df_io.info())\n",
    "\n",
    "# df_io['SCH_BUS_IND'] = df_io['SCH_BUS_IND'].apply(type_boolean)\n",
    "\n",
    "\n",
    "\n",
    "# df_io['ROAD_CONDITION'] = df_io['ROAD_CONDITION'].apply(ROAD_CONDITION)\n",
    "# df_io['INTERSECT_TYPE'] = df_io['INTERSECT_TYPE'].apply(INTERSECT_TYPE)\n",
    "# df_io['ILLUMINATION'] = df_io['ILLUMINATION'].apply(ILLUMINATION)\n",
    "# df_io['WEATHER'] = df_io['WEATHER'].apply(WEATHER)\n",
    "# df_io['TIME_OF_DAY'] = df_io['TIME_OF_DAY'].apply(TIME)\n",
    "\n",
    "# df_io = df_io.astype(\"Int64\")\n",
    "\n",
    "# print(df_io.head())\n",
    "# print(df_io.dtypes)\n",
    "# print(df_io.info())\n",
    "\n",
    "# drop col that will not be used\n",
    "static = ['ROAD_CONDITION', 'INTERSECT_TYPE', 'LANE_CLOSED', 'TIME_OF_DAY', 'SPEED_LIMIT', 'ILLUMINATION']\n",
    "dynamic = ['MOTORCYCLE_COUNT', 'HEAVY_TRUCK_COUNT', 'HAZARDOUS_TRUCK', 'AUTOMOBILE_COUNT', 'SCH_BUS_IND', 'WEATHER']\n",
    "label = ['PERSON_COUNT', 'FATAL_COUNT', 'INJURY_COUNT', 'MAX_SEVERITY_LEVEL', 'MAJOR_INJURY']\n",
    "categorical = ['ROAD_CONDITION', 'INTERSECT_TYPE', 'LANE_CLOSED', 'ILLUMINATION', 'HAZARDOUS_TRUCK', 'SCH_BUS_IND', 'WEATHER']\n",
    "gussian = ['TIME_OF_DAY', 'SPEED_LIMIT', 'MOTORCYCLE_COUNT', 'HEAVY_TRUCK_COUNT', 'AUTOMOBILE_COUNT']\n",
    "data = static + dynamic\n",
    "for col in df_io.columns:\n",
    "    if col not in static and col not in dynamic and col not in label:\n",
    "        df_io.drop(col, axis = 1, inplace = True)  \n",
    "# print(df_io[15:25])\n",
    "# df_io['TIME_OF_DAY'] = df_io['TIME_OF_DAY'].astype(\"Int64\")\n",
    "\n",
    "\n",
    "# clean data\n",
    "df_io['SCH_BUS_IND'] = df_io['SCH_BUS_IND'].apply(type_boolean)\n",
    "df_io['ROAD_CONDITION'] = df_io['ROAD_CONDITION'].apply(ROAD_CONDITION)\n",
    "df_io['INTERSECT_TYPE'] = df_io['INTERSECT_TYPE'].apply(INTERSECT_TYPE)\n",
    "df_io['ILLUMINATION'] = df_io['ILLUMINATION'].apply(ILLUMINATION)\n",
    "df_io['WEATHER'] = df_io['WEATHER'].apply(WEATHER)\n",
    "df_io['TIME_OF_DAY'] = df_io['TIME_OF_DAY'].apply(TIME)\n",
    "\n",
    "# drop rows contain nan\n",
    "df_io = df_io.dropna()\n",
    "df_io = df_io.astype(\"int64\")\n",
    "df_io[categorical] = df_io[categorical].astype(\"object\")\n",
    "print(df_io[15:25])\n",
    "# group data into dataset/label\n",
    "df_data = df_io[data].copy()\n",
    "df_label = df_io[label].copy()\n",
    "print(df_data.info())\n",
    "print(df_label.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# split the dataset with 33% as train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "comb_df_data = df_io[data].copy()\n",
    "static_df_data = df_io[static].copy()\n",
    "dynamic_df_data = df_io[dynamic].copy()\n",
    "\n",
    "sseverity_X_train, sseverity_X_test, sseverity_y_train, sseverity_y_test = train_test_split(static_df_data, df_io['MAX_SEVERITY_LEVEL'], test_size=0.33, random_state=42)\n",
    "# comb_X_train, comb_X_test, comb_y_train, comb_y_test = train_test_split(df_data, df_label, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class GaussianPredictor:\n",
    "    \n",
    "    \"\"\" Feature predictor for a normally distributed real-valued, continuous feature.\n",
    "\n",
    "        attr:\n",
    "            k : int -- number of classes\n",
    "            mu : np.ndarray[k] -- vector containing per class mean of the feature\n",
    "            sigma : np.ndarray[k] -- vector containing per class std. deviation of the feature\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        \"\"\" constructor\n",
    "\n",
    "        args : k -- number of classes\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.mu = np.zeros(k)\n",
    "        self.sigma = np.zeros(k)\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"update predictor statistics (mu, sigma) for Gaussian distribution\n",
    "\n",
    "        args:\n",
    "            x : pd.Series -- feature values\n",
    "            y : np.Series -- class labels\n",
    "            \n",
    "        return : GaussianPredictor -- return self for convenience\n",
    "        \n",
    "        \"\"\"\n",
    "        # df = pd.DataFrame({\"values\":x,\"labels\":y})\n",
    "        # groups = df.groupby(\"labels\")\n",
    "        # self.mu = np.array((groups.mean()))\n",
    "        # self.sigma = np.sqrt(np.array(groups.var(ddof=0)))\n",
    "        y=np.array(y)\n",
    "        x=np.array(x)\n",
    "        \n",
    "        \n",
    "        for i in range(self.k):\n",
    "            ybools = (y==i)\n",
    "            # given_i = np.array([x[j] for j in range(len(y)) if y[j] == i])\n",
    "            given_i = np.extract(ybools,x)\n",
    "            self.mu[i]=given_i.mean()\n",
    "            self.sigma[i]=np.sqrt(given_i.var())\n",
    "        return self\n",
    "            \n",
    "    def partial_log_likelihood(self, x):\n",
    "        \"\"\" log likelihood of feature values x according to each class\n",
    "\n",
    "        args:\n",
    "            x : pd.Series -- feature values\n",
    "\n",
    "        return: np.ndarray[self.k, len(x)] : log likelihood for this feature for each class\n",
    "        \"\"\"\n",
    "        logpdfs = np.zeros((self.k,len(x)))\n",
    "        for i in range(self.k):\n",
    "            logpdfs[i]=stats.norm(loc=self.mu[i],scale=self.sigma[i]).logpdf(x)\n",
    "        return logpdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class CategoricalPredictor:\n",
    "    \"\"\" Feature predictor for a categorical feature.\n",
    "\n",
    "        attr: \n",
    "            k : int -- number of classes\n",
    "            p : Dict[feature_value, np.ndarray[k]] -- dictionary of vectors containing per-class probability of a feature value;\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        \"\"\" constructor\n",
    "\n",
    "        args : k -- number of classes\n",
    "        \"\"\"\n",
    "        self.k=k\n",
    "\n",
    "    def fit(self, x, y, alpha=1.):\n",
    "        \"\"\" initializes the predictor statistics (p) for Categorical distribution\n",
    "        \n",
    "        args:\n",
    "            x : pd.Series -- feature values\n",
    "            y : pd.Series -- class labels\n",
    "        \n",
    "        kwargs:\n",
    "            alpha : float -- smoothing factor\n",
    "\n",
    "        return : CategoricalPredictor -- returns self for convenience:\n",
    "        \"\"\"\n",
    "        y=np.array(y)\n",
    "        x=np.array(x)\n",
    "        self.p = {}\n",
    "        for char in set(x):\n",
    "#             print(self.k)\n",
    "#             print(char)\n",
    "#             print(self.p)\n",
    "            self.p[char]=np.zeros(self.k)\n",
    "            \n",
    "        \n",
    "        for i in range(self.k):\n",
    "            # n=sum([1 for j in range(len(y)) if y[j] == i])\n",
    "            ybools= (y==i)\n",
    "            \n",
    "            n=np.sum( ybools )\n",
    "            for char in set(x):\n",
    "                xbools= (x == char)\n",
    "                # nj=sum([1 for j in range(len(y)) if x[j] == char and y[j] == i ])\n",
    "                nj = np.sum(np.logical_and(xbools,ybools))\n",
    "                (self.p[char])[i] = (nj + alpha)/ (n+len(set(x))*alpha)\n",
    "        return self\n",
    "\n",
    "    def partial_log_likelihood(self, x):\n",
    "        \"\"\" log likelihood of feature values x according to each class\n",
    "\n",
    "        args:\n",
    "            x : pd.Series -- vector of feature values\n",
    "\n",
    "        return : np.ndarray[self.k, len(x)] -- matrix of log likelihood for this feature\n",
    "        \"\"\"\n",
    "        like = np.zeros((self.k,len(x)))\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            for j,char in enumerate(x):\n",
    "                like[i][j]=np.log(self.p[char][i])\n",
    "        return like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, df_feature, df_label, alpha=1.):\n",
    "        self.predictor = {}\n",
    "        self.l = df_label.value_counts()\n",
    "        self.unique_label = len(df_label.unique())\n",
    "        self.log_prior = np.zeros(self.unique_label)\n",
    "        n = len(df_label)\n",
    "        # Initialize log_prior\n",
    "        for i in range(self.unique_label):\n",
    "            ybools= (label==i)\n",
    "            nt=np.sum( ybools )\n",
    "            self.log_prior[i] = np.log( (nt+alpha)/(n+(self.unique_label*alpha)))\n",
    "            \n",
    "        # Initialize predictor\n",
    "        for col in df_feature.columns:\n",
    "            if df_feature[col].dtype == 'object':\n",
    "#                 print(df_feature[col].shape)\n",
    "#                 print(df_feature[col].values.reshape(-1,1))\n",
    "#                 self.predictor[col] = CategoricalPredictor(self.unique_label).fit(df_feature[col], df_label)\n",
    "                self.predictor[col] = MultinomialNB().fit(df_feature[col].values.reshape(-1,1), df_label)\n",
    "            elif df_feature[col].dtype == 'int64':\n",
    "#                 self.predictor[col] = GaussianPredictor(self.unique_label).fit(df_feature[col], df_label)\n",
    "                self.predictor[col] = GaussianNB().fit(df_feature[col].values.reshape(-1,1), df_label)\n",
    "        \n",
    "    def log_likelihood(self, df_feature):\n",
    "        likelihood = np.array(([self.log_prior,]*len(df_feature))).transpose()\n",
    "        for col in self.predictor:\n",
    "            model = self.predictor[col]\n",
    "#             print(df_feature[col].values.reshape(-1,1))\n",
    "#             print(model.predict_log_proba(df_feature[col].values.reshape(-1,1)))\n",
    "#             print(collections.Counter(df_feature[col].values.reshape(-1,1)))\n",
    "#             unique, counts = np.unique(df_feature[col].values.reshape(-1,1), return_counts=True)\n",
    "#             p = dict(zip(unique, counts))\n",
    "#             print (p)\n",
    "\n",
    "            z = model.predict_log_proba(df_feature[col].values.reshape(-1,1)).T\n",
    "            likelihood += z\n",
    "#             likelihood += model.partial_log_likelihood(df_feature[col])\n",
    "#             print(col)\n",
    "#             for i in range(z.shape[0]):\n",
    "#                 print(collections.Counter(z[i]))\n",
    "#         print(likelihood.shape)\n",
    "        return likelihood \n",
    "        \n",
    "    def predict(self, df_feature):\n",
    "        pred = np.argmax(self.log_likelihood(df_feature),axis = 0)\n",
    "        return pred\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "    \n",
    "class NaiveBayesClassifier3:\n",
    "    \"\"\" Naive Bayes classifier for a mixture of continuous and categorical attributes.\n",
    "        We use GaussianPredictor for continuous attributes and CategoricalPredictor for categorical ones.\n",
    "        \n",
    "        attr:\n",
    "            predictor : Dict[column_name,model] -- model for each column\n",
    "            log_prior : np.ndarray -- the (log) prior probability of each class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, label, alpha=1.):\n",
    "        \"\"\"initialize predictors for each feature and compute class prior\n",
    "        \n",
    "        args:\n",
    "            df : pd.DataFrame -- processed dataframe, without any missing values.\n",
    "        \n",
    "        kwargs:\n",
    "            alpha : float -- smoothing factor for prior probability\n",
    "        \"\"\"\n",
    "        # label = df[\"label\"]\n",
    "        self.predictor = {}\n",
    "        self.l = label.value_counts()\n",
    "        self.unique_label = len(label.unique())\n",
    "        self.log_prior = np.zeros(self.unique_label)\n",
    "        n = len(label)\n",
    "        # Initialize log_prior\n",
    "        for i in range(self.unique_label):\n",
    "            ybools= (label==i)\n",
    "            nt=np.sum( ybools )\n",
    "            self.log_prior[i] = np.log( (nt+alpha)/(n+(self.unique_label*alpha)))\n",
    "\n",
    "    def log_likelihood(self, x):\n",
    "        \"\"\"log_likelihood for input instances from log_prior and partial_log_likelihood of feature predictors\n",
    "\n",
    "        args:\n",
    "            x : pd.DataFrame -- processed dataframe (ignore label if present)\n",
    "\n",
    "        returns : np.ndarray[num_classes, len(x)] -- array of log-likelihood\n",
    "        \"\"\"\n",
    "        # try:\n",
    "        #     x = x.drop(\"label\")\n",
    "        # except:\n",
    "        #     pass\n",
    "        \n",
    "        # like = np.zeros((self.k, len(x)))\n",
    "        like = np.array(([self.log_prior,]*len(x))).transpose()\n",
    "        # print (self.k,len(x))\n",
    "        # print(like.shape)\n",
    "        # for i in range(self.k):\n",
    "        #     for j in range(len(x)):\n",
    "        #         \n",
    "        #         # like[i][j] = self.log_prior[i]+np.sum( self.predictor[key].partial_log_likelihood(x[j])[i][j] for key in self.predictor )\n",
    "        #         like[i][j]=self.log_prior[i]\n",
    "        for key in self.predictor:\n",
    "            model = self.predictor[key]\n",
    "            z= model.partial_log_likelihood(x[key])\n",
    "            like +=z\n",
    "            print(key)\n",
    "            for i in range(z.shape[0]):\n",
    "                print(collections.Counter(z[i]))\n",
    "            # like[i][j] += model.partial_log_likelihood(x[key])[i][j]\n",
    "                             \n",
    "        return like           \n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"predicts label for input instances, breaks ties in favor of the class with lower id.\n",
    "\n",
    "        args:\n",
    "            x : pd.DataFrame -- processed dataframe (ignore label if present)\n",
    "\n",
    "        returns : np.ndarray[len(x)] -- vector of class labels\n",
    "        \"\"\"\n",
    "        pred = np.argmax(self.log_likelihood(x),axis = 0)\n",
    "        return pred\n",
    "\n",
    "class NaiveBayesClassifier2:\n",
    "    \"\"\" Naive Bayes classifier for a mixture of continuous and categorical attributes.\n",
    "        We use GaussianPredictor for continuous attributes and CategoricalPredictor for categorical ones.\n",
    "        \n",
    "        attr:\n",
    "            predictor : Dict[column_name,model] -- model for each column\n",
    "            log_prior : np.ndarray -- the (log) prior probability of each class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, label, alpha=1.):\n",
    "        \"\"\"initialize predictors for each feature and compute class prior\n",
    "        \n",
    "        args:\n",
    "            df : pd.DataFrame -- processed dataframe, without any missing values.\n",
    "        \n",
    "        kwargs:\n",
    "            alpha : float -- smoothing factor for prior probability\n",
    "        \"\"\"\n",
    "        # label = df[\"label\"]\n",
    "        k = max(label)+1\n",
    "        self.log_prior = np.zeros(k)\n",
    "        n = len(label)\n",
    "        for i in range(k):\n",
    "            ybools= (label==i)\n",
    "            \n",
    "            nt=np.sum( ybools )\n",
    "            self.log_prior[i] = np.log( (nt+alpha)/(n+(k*alpha)))\n",
    "        \n",
    "        self.predictor = dict()\n",
    "        types = dict(df.dtypes)\n",
    "        for key in types:\n",
    "            if key != \"label\" and key!= \"index\":\n",
    "                if str(types[key])==\"int64\":\n",
    "                    self.predictor[key]=GaussianPredictor(k).fit(df[key],label)\n",
    "                elif str(types[key])==\"object\":\n",
    "                    self.predictor[key]=CategoricalPredictor(k).fit(df[key],label)\n",
    "                else:\n",
    "                    raise TypeError\n",
    "        self.k=k            \n",
    "        pass\n",
    "\n",
    "    def log_likelihood(self, x):\n",
    "        \"\"\"log_likelihood for input instances from log_prior and partial_log_likelihood of feature predictors\n",
    "\n",
    "        args:\n",
    "            x : pd.DataFrame -- processed dataframe (ignore label if present)\n",
    "\n",
    "        returns : np.ndarray[num_classes, len(x)] -- array of log-likelihood\n",
    "        \"\"\"\n",
    "        # try:\n",
    "        #     x = x.drop(\"label\")\n",
    "        # except:\n",
    "        #     pass\n",
    "        \n",
    "        # like = np.zeros((self.k, len(x)))\n",
    "        like = np.array(([self.log_prior,]*len(x))).transpose()\n",
    "        # print (self.k,len(x))\n",
    "        # print(like.shape)\n",
    "        # for i in range(self.k):\n",
    "        #     for j in range(len(x)):\n",
    "        #         \n",
    "        #         # like[i][j] = self.log_prior[i]+np.sum( self.predictor[key].partial_log_likelihood(x[j])[i][j] for key in self.predictor )\n",
    "        #         like[i][j]=self.log_prior[i]\n",
    "        for key in self.predictor:\n",
    "            model = self.predictor[key]\n",
    "            z= model.partial_log_likelihood(x[key])\n",
    "            like +=z\n",
    "            print(key)\n",
    "            for i in range(z.shape[0]):\n",
    "                print(collections.Counter(z[i]))\n",
    "            # like[i][j] += model.partial_log_likelihood(x[key])[i][j]\n",
    "                             \n",
    "        return like           \n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"predicts label for input instances, breaks ties in favor of the class with lower id.\n",
    "\n",
    "        args:\n",
    "            x : pd.DataFrame -- processed dataframe (ignore label if present)\n",
    "\n",
    "        returns : np.ndarray[len(x)] -- vector of class labels\n",
    "        \"\"\"\n",
    "        pred = np.argmax(self.log_likelihood(x),axis = 0)\n",
    "        return pred\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Static Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0 8 4 9 3 2 1]\n{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 8: 5, 9: 6}\n",
      "ROAD_CONDITION\nCounter({-0.46127217039111407: 9681, -1.714035138886482: 2308, -1.9726589396914451: 1770, -2.9898504386905347: 633})\nCounter({-0.266404674004496: 9681, -2.0476928433652555: 2308, -3.028522096376982: 1770, -2.8743714165497236: 633})\nCounter({-0.26354699671654047: 9681, -2.0961284604648505: 2308, -2.789275641024796: 1770, -3.051639905492287: 633})\nCounter({-0.28499510263095557: 9681, -2.1414123606930677: 2308, -2.357898730978098: 1770, -3.3277302297802827: 633})\nCounter({-0.31086813002916874: 9681, -2.035727508443403: 2308, -2.3141416739644023: 1770, -3.2766888821386795: 633})\nCounter({-0.3036197787413602: 9681, -2.0142097796132883: 2308, -2.4280256669388725: 1770, -3.213343307298475: 633})\nCounter({-0.3246026610658291: 9681, -2.031565593633807: 2308, -2.189789598848701: 1770, -3.378014046206498: 633})\n",
      "INTERSECT_TYPE\nCounter({-0.42535893051634927: 9093, -1.840914463755419: 2420, -1.9822485224842066: 2183, -3.8761374867886413: 306, -4.4350204055084115: 153, -4.645424931045191: 117, -5.1333089855687755: 90, -6.572525748143009: 20, -7.762109815016845: 8, -9.014872783512212: 2})\nCounter({-0.30318625898774615: 9093, -2.469639177657212: 2420, -2.382627800667582: 2183, -4.174387269895637: 306, -4.867534450455582: 273, -3.481240089335692: 117})\nCounter({-0.43743941274067843: 9093, -1.7709974777796258: 2420, -2.0361052281928678: 2183, -4.675162557808126: 360, -3.982015377248181: 306, -6.061456918928017: 30})\nCounter({-0.4935341266559297: 9093, -1.7514384946517163: 2420, -1.8207996224492187: 2183, -3.7234597877107154: 306, -4.416606968270661: 153, -4.621401380916674: 117, -5.073386504659731: 90, -7.0192966537150445: 20, -7.71244383427499: 10})\nCounter({-0.49110277893759646: 9093, -1.7970567690389936: 2420, -1.7948613784755578: 2183, -3.8398167440842244: 306, -4.266695946696205: 153, -4.567450100715339: 117, -4.760353766839831: 90, -6.818741899321834: 20, -8.610501368549889: 8, -7.917354187989944: 2})\nCounter({-0.6029101429696446: 9093, -1.640659686234053: 2420, -1.5905099025485814: 2183, -3.659140528124202: 306, -4.407550387359197: 153, -5.013686190929512: 117, -4.859535511102254: 90, -6.399980552049403: 20, -7.498592840717513: 10})\nCounter({-0.4905522974731232: 9093, -1.7084626096428408: 2420, -1.9084837435361965: 2183, -3.6312503412773: 306, -4.3652195163575005: 153, -5.240688253711401: 117, -5.058366696917446: 90, -6.156978985585555: 20, -5.4638318050256105: 8, -6.8501261661455: 2})\n",
      "LANE_CLOSED\nCounter({-0.530768137997263: 7837, -1.3085700307783177: 3943, -1.9553199704119344: 2609, -9.01450795315428: 3})\nCounter({-1.987068221548821: 7837, -2.181224235989778: 3943, -0.29849298855599654: 2609, -4.820281565605037: 3})\nCounter({-1.2270906134412412: 7837, -1.5365126725294278: 3943, -0.714653385780909: 2609, -6.0473721790462776: 3})\nCounter({-0.8345247771775874: 7837, -1.243612140216545: 3943, -1.2848878405487767: 2609, -7.016609683894219: 3})\nCounter({-0.6560893288436171: 7837, -1.2499400371484273: 3943, -1.6414984736021643: 2609, -6.999969762969948: 3})\nCounter({-0.8160751903688891: 7837, -1.1770612600794195: 3943, -1.3910211876602534: 2609, -7.09146476105094: 3})\nCounter({-0.4043995779061261: 7837, -1.612641332151638: 3943, -2.023468383401188: 2609, -6.843749949006225: 3})\nTIME_OF_DAY\nCounter({-3.1052447048417173: 953, -3.0487563040617123: 937, -2.9421936056890874: 879, -2.8605668047499346: 836, -2.9873843263130917: 823, -3.1802548998678093: 756, -2.8944598452179378: 713, -2.8038759012442545: 691, -3.3366893931073793: 628, -2.7834185753280476: 626, -2.765301786533311: 624, -2.772120895172047: 623, -2.826471261556257: 616, -3.248040980803816: 567, -3.518059783780421: 525, -3.9556082574269213: 522, -4.21178634040038: 507, -3.7243660718869354: 486, -4.068585058986932: 459, -4.628472482679324: 426, -4.336060822116392: 397, -3.4157731541993863: 297, -3.8260451932909447: 280, -3.6084412250284297: 221})\nCounter({-3.0583120704360267: 1789, -2.9928915096883633: 1514, -3.142424219968737: 1446, -2.9461625377257468: 1336, -2.9181251545481763: 1240, -3.2452279582864945: 1234, -3.6657887059500456: 984, -3.3667232853892983: 977, -4.039620481650981: 948, -3.5069102012771483: 908, -3.84335879940799: 883, -2.908779360155653: 626, -4.2545737526790175: 507})\nCounter({-3.0972207216097383: 953, -3.113290635943944: 937, -3.01394227845522: 879, -2.9363142245343417: 836, -3.0010863469878557: 823, -3.2343592970005126: 756, -2.9266722759338184: 713, -2.8804064741813082: 691, -3.377148261624926: 628, -2.8430050445292787: 626, -2.8337518841787768: 624, -2.84621902739612: 623, -2.8739785084476264: 616, -3.215075399799466: 567, -3.541657529817185: 525, -3.9358369769052386: 522, -4.165507155801032: 507, -3.7278871015772896: 486, -3.903697148236828: 459, -4.37832984386258: 426, -4.130153344265782: 397, -3.3546503815570388: 297, -3.69896125577572: 280, -3.5159456668824567: 221})\nCounter({-3.16295300121502: 953, -2.9958371387214946: 937, -2.898825926424812: 879, -2.8270864471383597: 836, -3.0325186164196323: 823, -3.1181200840284076: 756, -2.927355964634475: 713, -2.780618700862137: 691, -3.2656747623455504: 628, -2.7928458600948494: 626, -2.763498407340382: 624, -2.7594226875961443: 623, -2.847465045859547: 616, -3.318659119020638: 567, -3.438501173672923: 525, -3.8599691953583593: 522, -4.108610805716422: 507, -3.6365993180105263: 486, -4.194200920345409: 459, -4.783602219069175: 426, -4.476265703202177: 397, -3.4996369698364855: 297, -3.937407870498871: 280, -3.7058865536625634: 221})\nCounter({-3.1517683045878613: 953, -2.975015493141216: 937, -2.86757079315976: 879, -2.787930533428553: 836, -3.0089730423170766: 823, -3.1102646333729207: 756, -2.8939822202965404: 713, -2.736094713947595: 691, -3.273318213854875: 628, -2.7474138970062154: 626, -2.715836395736426: 624, -2.7120633347168863: 623, -2.8067958385262535: 616, -3.3223680071088957: 567, -3.4641762345870775: 525, -3.9293055968022306: 522, -4.20357693828518: 507, -3.6828386955695294: 486, -4.282811219695522: 459, -4.9298594674903295: 426, -4.592433123467801: 397, -3.520772149880179: 297, -4.000993756173491: 280, -3.7469807329017106: 221})\nCounter({-3.165964797036656: 953, -2.9447396503088332: 937, -2.8318398339024817: 879, -2.7489449799581593: 836, -3.00881995128474: 823, -3.0876444291772147: 756, -2.8816800679948535: 713, -2.6960550884758674: 691, -3.260554170507626: 628, -2.7174151888011693: 626, -2.680290192897372: 624, -2.673170159455605: 623, -2.7845451471669964: 616, -3.3531146052506027: 567, -3.4634688743000677: 525, -3.9593131692710393: 522, -4.25224276044957: 507, -3.6963885405545382: 486, -4.401763462726685: 459, -5.106117666236905: 426, -4.7389380832507815: 397, -3.5702693759265784: 297, -4.09459380466462: 280, -3.8174291090645847: 221})\nCounter({-3.026561253822268: 953, -3.3477671532798943: 937, -3.2361863870292225: 879, -3.1422634377351972: 836, -2.9792216674631216: 823, -3.477005736487212: 756, -2.949539898060622: 713, -3.0659983053978186: 691, -3.6239021366511768: 628, -2.9431498101255613: 626, -2.9664414915930006: 624, -3.0073909900170865: 623, -2.937515945614768: 616, -3.091558657138061: 567, -3.7884563537717875: 525, -4.170538238882949: 522, -4.388065906873498: 507, -3.9706683878490447: 486, -3.5281264399676964: 459, -3.8523572331223925: 426, -3.681412928066721: 397, -3.1742138774104998: 297, -3.3924977688253177: 280, -3.2745269146395857: 221})\nSPEED_LIMIT\nCounter({-3.8028065600751377: 5186, -3.401054715056894: 3801, -4.700416206591698: 2064, -3.4630369402441836: 1370, -3.7002579305624144: 714, -3.5143112550005453: 397, -6.401529543144745: 377, -4.905513465617144: 212, -4.112717686011585: 107, -4.26654063028067: 99, -7.873864562412212: 52, -5.719725066084559: 11, -8.803597940221556: 1, -5.463353492302751: 1})",
      "\nCounter({-4.068029221514222: 5186, -3.3428228894887857: 3801, -4.490164250603655: 2064, -3.3049389766217856: 1370, -3.4835345658519303: 714, -3.5971863044529315: 397, -6.36271194374396: 377, -5.659153561928239: 212, -3.8786096571792203: 107, -4.755351640672658: 99, -9.669436338277853: 52, -6.779434985280966: 11, -9.101177645272847: 1, -5.318198346125236: 1})\nCounter({-3.6999320799302398: 5186, -3.2359322128180303: 3801, -5.22417164339385: 2064, -3.368462174861955: 1370, -3.7440120673059: 714, -3.346422181174125: 397, -7.67641094108188: 377, -5.13601166864253: 212, -4.362581890149865: 107, -4.296461909086375: 99, -9.112780529711113: 52, -6.218581358598703: 11, -11.100729960369987: 1, -6.328781327037854: 1})\nCounter({-3.7695672252302725: 5186, -3.382340876674899: 3801, -4.784569623716328: 2064, -3.460812882916234: 1370, -3.720675009503584: 714, -3.4852589907795783: 397, -6.574024719313128: 377, -4.882354055169705: 212, -4.1619272564369485: 107, -4.235265580026981: 99, -7.91196020267396: 52, -5.710832650658442: 11, -9.089040296293987: 1, -5.58860211134172: 1})\nCounter({-3.8901604016816136: 5186, -3.4101704399898827: 3801, -4.5566102203380945: 2064, -3.4334779221104763: 1370, -3.6323203795420427: 714, -3.5623979331802618: 397, -6.183039962378038: 377, -5.072290264617236: 212, -4.006697812284582: 107, -4.393457845493939: 99, -8.161997373852966: 52, -5.926657659051507: 11, -8.51160960566187: 1, -5.2820576037025795: 1})\nCounter({-3.6403397330529326: 5186, -3.261934770625859: 3801, -5.294554261738737: 2064, -3.4214109664082: 1370, -3.813339613521127: 714, -3.334911026174103: 397, -7.705578715278689: 377, -4.948554500802349: 212, -4.437720711964639: 107, -4.178220891262348: 99, -8.654270037405864: 52, -5.951340561672934: 11, -11.046412974140983: 1, -6.38384026284342: 1})\nCounter({-3.351128087352052: 5186, -3.274293796806808: 3801, -6.4327741712205215: 2064, -3.6498952709722117: 1370, -4.301509158096298: 714, -3.1747047356000886: 397, -9.66808883617948: 377, -4.532012029732029: 212, -5.229135458179068: 107, -3.8035638520626986: 99, -8.37343104049212: 52, -5.536472620360043: 11, -14.007453152973168: 1, -7.912425297220658: 1})\n",
      "ILLUMINATION\nCounter({-0.6100453310296289: 7958, -1.1486741641297102: 4528, -2.3999039778594513: 1220, -3.7288909937220356: 345, -3.9147631502390134: 252, -5.313327603950719: 89})\nCounter({-0.9861343052414194: 7958, -0.924258901523332: 4528, -1.9459101490553135: 1220, -3.4499875458315876: 345, -3.2268439945173775: 252, -4.143134726391533: 89})\nCounter({-0.7438214715232121: 7958, -0.9706848039399538: 4528, -2.3885275227947704: 1220, -3.7495040759303713: 597, -4.953476880256307: 89})\nCounter({-0.6007738604289302: 7958, -1.1797756957753163: 4528, -2.3731152437998837: 1220, -3.9970812567968936: 345, -3.6676020556666513: 252, -4.93806460126142: 89})\nCounter({-0.5286065949838975: 7958, -1.255410042287854: 4528, -2.536727838608926: 1220, -3.734575049508179: 345, -3.9847995594250594: 252, -5.518729919351014: 89})\nCounter({-0.5040103459589191: 7958, -1.2828764019214018: 4528, -2.6975702375629904: 1220, -3.8086050462296575: 597, -4.9717558560353385: 89})\nCounter({-0.9965550953171903: 7958, -0.6700126051582884: 4528, -2.5692137562479944: 1220, -4.137829674161839: 345, -4.012666531207834: 252, -4.7664383335842135: 89})\nCounter({0: 14387, 4: 4, 5: 1})\nCounter({0: 8121, 4: 2625, 5: 1778, 3: 1155, 6: 478, 2: 172, 1: 63})\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "def label_normalization(label,label_test):\n",
    "    # print(label)\n",
    "    labellist = pd.Series(np.append(label,label_test)).unique()\n",
    "    print(labellist)\n",
    "    labellist.sort()\n",
    "    revdic = dict()\n",
    "    for i,z in enumerate(labellist):\n",
    "        revdic[z] = i\n",
    "    print (revdic)\n",
    "    f = (lambda s: revdic[s])\n",
    "    return np.array(list(map(f, label))),np.array(list(map(f, label_test)))\n",
    "\n",
    "lab_train,lab_test=label_normalization(sseverity_y_train,sseverity_y_test)\n",
    "\n",
    "\n",
    "# classifier = NaiveBayesClassifier(sseverity_X_train, sseverity_y_train)\n",
    "# predict = classifier.predict(sseverity_X_test)\n",
    "# c = collections.Counter(predict)\n",
    "# d = collections.Counter(sseverity_y_test)\n",
    "# print(c)\n",
    "# print(d)\n",
    "\n",
    "classifier = NaiveBayesClassifier2(sseverity_X_train, pd.Series(lab_train))\n",
    "predict = classifier.predict(sseverity_X_test)\n",
    "c = collections.Counter(predict)\n",
    "d = collections.Counter(lab_test)\n",
    "print(c)\n",
    "print(d)\n",
    "# print(sseverity_y_test)\n",
    "# print(label_normalization(sseverity_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Severity Prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}