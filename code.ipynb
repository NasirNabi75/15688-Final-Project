{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carcrash Severity Prediction\n",
    "\n",
    "Downloading the datasets:\n",
    "\n",
    "Please run `wget https://data.wprdc.org/dataset/3130f583-9499-472b-bb5a-f63a6ff6059a/resource/ec578660-2d3f-489d-9ba1-af0ebfc3b140/download/all-crashes-2004-2018.csv.zip`\n",
    "or visit this link to get the Allegheny County crash data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import ckanapi\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "site = \"https://data.wprdc.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_resource_data(site,resource_id,count=50):\n",
    "    # Use the datastore_search API endpoint to get <count> records from\n",
    "    # a CKAN resource.\n",
    "    ckan = ckanapi.RemoteCKAN(site)\n",
    "    response = ckan.action.datastore_search(id=resource_id, limit=count)\n",
    "\n",
    "    # A typical response is a dictionary like this\n",
    "    #{u'_links': {u'next': u'/api/action/datastore_search?offset=3',\n",
    "    #             u'start': u'/api/action/datastore_search'},\n",
    "    # u'fields': [{u'id': u'_id', u'type': u'int4'},\n",
    "    #             {u'id': u'pin', u'type': u'text'},\n",
    "    #             {u'id': u'number', u'type': u'int4'},\n",
    "    #             {u'id': u'total_amount', u'type': u'float8'}],\n",
    "    # u'limit': 3,\n",
    "    # u'records': [{u'_id': 1,\n",
    "    #               u'number': 11,\n",
    "    #               u'pin': u'0001B00010000000',\n",
    "    #               u'total_amount': 13585.47},\n",
    "    #              {u'_id': 2,\n",
    "    #               u'number': 2,\n",
    "    #               u'pin': u'0001C00058000000',\n",
    "    #               u'total_amount': 7827.64},\n",
    "    #              {u'_id': 3,\n",
    "    #               u'number': 1,\n",
    "    #               u'pin': u'0001C01661006700',\n",
    "    #               u'total_amount': 3233.59}],\n",
    "    # u'resource_id': u'd1e80180-5b2e-4dab-8ec3-be621628649e',\n",
    "    # u'total': 88232}\n",
    "    data = response['records']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "crash_data_2017 = get_resource_data(site,resource_id=\"bf8b3c7e-8d60-40df-9134-21606a451c1a\",count=999999999) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ACCESS_CTRL ADJ_RDWY_SEQ  AGGRESSIVE_DRIVING  ALCOHOL_RELATED  \\\n",
      "0        None         None                   0                0   \n",
      "1        None         None                   1                0   \n",
      "2        None         None                   0                0   \n",
      "3        None         None                   0                0   \n",
      "4        None         None                   0                1   \n",
      "\n",
      "   AUTOMOBILE_COUNT  BELTED_DEATH_COUNT  BELTED_MAJ_INJ_COUNT  BICYCLE  \\\n",
      "0                 2                   0                     0        0   \n",
      "1                 1                   0                     0        0   \n",
      "2                 1                   0                     0        0   \n",
      "3                 1                   0                     0        0   \n",
      "4                 4                   0                     0        0   \n",
      "\n",
      "   BICYCLE_COUNT  BICYCLE_DEATH_COUNT  ...  WORK_ZONE_LOC  WORK_ZONE_TYPE  \\\n",
      "0              0                    0  ...           None            None   \n",
      "1              0                    0  ...           None            None   \n",
      "2              0                    0  ...           None            None   \n",
      "3              0                    0  ...           None            None   \n",
      "4              0                    0  ...           None            None   \n",
      "\n",
      "   WZ_CLOSE_DETOUR WZ_FLAGGER  WZ_LAW_OFFCR_IND  WZ_LN_CLOSURE  WZ_MOVING  \\\n",
      "0             None       None              None           None       None   \n",
      "1             None       None              None           None       None   \n",
      "2             None       None              None           None       None   \n",
      "3             None       None              None           None       None   \n",
      "4             None       None              None           None       None   \n",
      "\n",
      "  WZ_OTHER WZ_SHLDER_MDN _id  \n",
      "0     None          None   1  \n",
      "1     None          None   2  \n",
      "2     None          None   3  \n",
      "3     None          None   4  \n",
      "4     None          None   5  \n",
      "\n",
      "[5 rows x 191 columns]\n"
     ]
    }
   ],
   "source": [
    "len(crash_data_2017)\n",
    "df = pd.DataFrame(crash_data_2017)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add a graph/animation to show the car crash data\n",
    "maybe the geospatial data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanxuan/anoconda3/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (79,183,189) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TIME_OF_DAY ILLUMINATION WEATHER ROAD_CONDITION INTERSECT_TYPE  \\\n",
      "29           11            1       1              5              0   \n",
      "48           13            1       4              2              0   \n",
      "52           10            1       2              2              0   \n",
      "53           15            1       1              2              0   \n",
      "54           16            1       1              3              0   \n",
      "59           13            1       2              2              0   \n",
      "61           11            1       4              5              0   \n",
      "67           21            2       4              4              2   \n",
      "69            7            1       4              5              0   \n",
      "70           10            1       4              3              0   \n",
      "\n",
      "   SCH_BUS_IND  PERSON_COUNT  AUTOMOBILE_COUNT  MOTORCYCLE_COUNT  \\\n",
      "29           0             2                 2                 0   \n",
      "48           0             3                 2                 0   \n",
      "52           0             4                 2                 0   \n",
      "53           0             3                 2                 0   \n",
      "54           0             1                 1                 0   \n",
      "59           0             2                 2                 0   \n",
      "61           0             3                 1                 0   \n",
      "67           0             1                 1                 0   \n",
      "69           0             2                 2                 0   \n",
      "70           0             2                 1                 0   \n",
      "\n",
      "    HEAVY_TRUCK_COUNT  FATAL_COUNT  INJURY_COUNT  MAX_SEVERITY_LEVEL  \\\n",
      "29                  0            0             0                   0   \n",
      "48                  0            0             0                   0   \n",
      "52                  0            0             0                   0   \n",
      "53                  0            0             2                   4   \n",
      "54                  0            0             1                   4   \n",
      "59                  0            0             1                   4   \n",
      "61                  0            0             0                   0   \n",
      "67                  0            0             0                   0   \n",
      "69                  0            0             2                   3   \n",
      "70                  0            0             0                   0   \n",
      "\n",
      "   LANE_CLOSED HAZARDOUS_TRUCK  MAJOR_INJURY  SPEED_LIMIT  \n",
      "29           0               0             0           40  \n",
      "48           1               0             0           35  \n",
      "52           0               0             0           40  \n",
      "53           2               0             0           25  \n",
      "54           2               0             0           45  \n",
      "59           2               0             0           40  \n",
      "61           2               0             0           35  \n",
      "67           0               0             0           45  \n",
      "69           1               0             0           35  \n",
      "70           0               0             0           35  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43610 entries, 1 to 180963\n",
      "Data columns (total 12 columns):\n",
      "ROAD_CONDITION       43610 non-null object\n",
      "INTERSECT_TYPE       43610 non-null object\n",
      "LANE_CLOSED          43610 non-null object\n",
      "TIME_OF_DAY          43610 non-null int64\n",
      "SPEED_LIMIT          43610 non-null int64\n",
      "ILLUMINATION         43610 non-null object\n",
      "MOTORCYCLE_COUNT     43610 non-null int64\n",
      "HEAVY_TRUCK_COUNT    43610 non-null int64\n",
      "HAZARDOUS_TRUCK      43610 non-null object\n",
      "AUTOMOBILE_COUNT     43610 non-null int64\n",
      "SCH_BUS_IND          43610 non-null object\n",
      "WEATHER              43610 non-null object\n",
      "dtypes: int64(5), object(7)\n",
      "memory usage: 4.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43610 entries, 1 to 180963\n",
      "Data columns (total 5 columns):\n",
      "PERSON_COUNT          43610 non-null int64\n",
      "FATAL_COUNT           43610 non-null int64\n",
      "INJURY_COUNT          43610 non-null int64\n",
      "MAX_SEVERITY_LEVEL    43610 non-null int64\n",
      "MAJOR_INJURY          43610 non-null int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 2.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "#clean sch_bus_ind y/n to integer 0,1\n",
    "\n",
    "def type_boolean(c):\n",
    "    if c == \"Y\": return 1\n",
    "    elif c == \"N\": return 0\n",
    "    # elif c == \"nan\": return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    # raise ValueError(c)\n",
    "\n",
    "def ROAD_CONDITION(c): # 8 is other 9 is unknown, 1,7->2, 3->4, 4->3, 5,6->5, 2,8,9->nan\n",
    "    if c == 1 or c == 7:\n",
    "        return 2\n",
    "    elif c == 3:\n",
    "        return 4\n",
    "    elif c == 4:\n",
    "        return 3\n",
    "    elif c == 5 or c == 6:\n",
    "        return 5\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def INTERSECT_TYPE(c): # 10 is other 99 is unkonw\n",
    "    if c <= 9:\n",
    "        return c\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def ILLUMINATION(c):\n",
    "    if c <= 6:\n",
    "        return c\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def WEATHER(c):\n",
    "    if c <= 7:\n",
    "        return c\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def TIME(c): # extract only the hour\n",
    "    if c <= 2500:\n",
    "        return c // 100\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "if not Path('all-crashes-2004-2018.csv.zip').exists():\n",
    "    wget.download(\"https://data.wprdc.org/dataset/3130f583-9499-472b-bb5a-f63a6ff6059a/resource/ec578660-2d3f-489d-9ba1-af0ebfc3b140/download/all-crashes-2004-2018.csv.zip\")\n",
    "# zf = zipfile.ZipFile('all-crashes-2004-2018.csv.zip') \n",
    "df_io = pd.read_csv('all-crashes-2004-2018.csv.zip')\n",
    "# print(df.head())\n",
    "# print(list(df))\n",
    "# static_columns = \"ROAD_CONDITION,INTERSECT_TYPE,URBAN_RURAL,DISTRICT,STATE_ROAD,LOCAL_ROAD,SNOW_SLUSH_ROAD,LANE_CLOSED,TIME_OF_DAY,SPEED_LIMIT\"\n",
    "# dynamic_columns = \"ILLUMINATION,MOTORCYCLE_COUNT,HEAVY_TRUCK_COUNT,WEATHER,HAZARDOUS_TRUCK,SCH_BUS_IND,AUTOMOBILE_COUNT\"\n",
    "# output_columns = \"PERSON_COUNT,FATAL_COUNT,INJURY_COUNT,MAX_SEVERITY_LEVEL,MAJOR_INJURY\"\n",
    "# df_io = df[(static_columns+\",\"+dynamic_columns+\",\"+output_columns).split(',')]\n",
    "# print(df_io.head())\n",
    "# print(df_io.dtypes)\n",
    "# print(df_io.info())\n",
    "\n",
    "# df_io['SCH_BUS_IND'] = df_io['SCH_BUS_IND'].apply(type_boolean)\n",
    "\n",
    "\n",
    "\n",
    "# df_io['ROAD_CONDITION'] = df_io['ROAD_CONDITION'].apply(ROAD_CONDITION)\n",
    "# df_io['INTERSECT_TYPE'] = df_io['INTERSECT_TYPE'].apply(INTERSECT_TYPE)\n",
    "# df_io['ILLUMINATION'] = df_io['ILLUMINATION'].apply(ILLUMINATION)\n",
    "# df_io['WEATHER'] = df_io['WEATHER'].apply(WEATHER)\n",
    "# df_io['TIME_OF_DAY'] = df_io['TIME_OF_DAY'].apply(TIME)\n",
    "\n",
    "# df_io = df_io.astype(\"Int64\")\n",
    "\n",
    "# print(df_io.head())\n",
    "# print(df_io.dtypes)\n",
    "# print(df_io.info())\n",
    "\n",
    "# drop col that will not be used\n",
    "static = ['ROAD_CONDITION', 'INTERSECT_TYPE', 'LANE_CLOSED', 'TIME_OF_DAY', 'SPEED_LIMIT', 'ILLUMINATION']\n",
    "dynamic = ['MOTORCYCLE_COUNT', 'HEAVY_TRUCK_COUNT', 'HAZARDOUS_TRUCK', 'AUTOMOBILE_COUNT', 'SCH_BUS_IND', 'WEATHER']\n",
    "label = ['PERSON_COUNT', 'FATAL_COUNT', 'INJURY_COUNT', 'MAX_SEVERITY_LEVEL', 'MAJOR_INJURY']\n",
    "categorical = ['ROAD_CONDITION', 'INTERSECT_TYPE', 'LANE_CLOSED', 'ILLUMINATION', 'HAZARDOUS_TRUCK', 'SCH_BUS_IND', 'WEATHER']\n",
    "gussian = ['TIME_OF_DAY', 'SPEED_LIMIT', 'MOTORCYCLE_COUNT', 'HEAVY_TRUCK_COUNT', 'AUTOMOBILE_COUNT']\n",
    "data = static + dynamic\n",
    "for col in df_io.columns:\n",
    "    if col not in static and col not in dynamic and col not in label:\n",
    "        df_io.drop(col, axis = 1, inplace = True)  \n",
    "# print(df_io[15:25])\n",
    "# df_io['TIME_OF_DAY'] = df_io['TIME_OF_DAY'].astype(\"Int64\")\n",
    "\n",
    "\n",
    "# clean data\n",
    "df_io['SCH_BUS_IND'] = df_io['SCH_BUS_IND'].apply(type_boolean)\n",
    "df_io['ROAD_CONDITION'] = df_io['ROAD_CONDITION'].apply(ROAD_CONDITION)\n",
    "df_io['INTERSECT_TYPE'] = df_io['INTERSECT_TYPE'].apply(INTERSECT_TYPE)\n",
    "df_io['ILLUMINATION'] = df_io['ILLUMINATION'].apply(ILLUMINATION)\n",
    "df_io['WEATHER'] = df_io['WEATHER'].apply(WEATHER)\n",
    "df_io['TIME_OF_DAY'] = df_io['TIME_OF_DAY'].apply(TIME)\n",
    "\n",
    "# drop rows contain nan\n",
    "df_io = df_io.dropna()\n",
    "df_io = df_io.astype(\"int64\")\n",
    "df_io[categorical] = df_io[categorical].astype(\"object\")\n",
    "print(df_io[15:25])\n",
    "# group data into dataset/label\n",
    "df_data = df_io[data].copy()\n",
    "df_label = df_io[label].copy()\n",
    "print(df_data.info())\n",
    "print(df_label.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset with 33% as train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "comb_df_data = df_io[data].copy()\n",
    "static_df_data = df_io[static].copy()\n",
    "dynamic_df_data = df_io[dynamic].copy()\n",
    "\n",
    "sseverity_X_train, sseverity_X_test, sseverity_y_train, sseverity_y_test = train_test_split(static_df_data, df_io['MAX_SEVERITY_LEVEL'], test_size=0.33, random_state=42)\n",
    "# comb_X_train, comb_X_test, comb_y_train, comb_y_test = train_test_split(df_data, df_label, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPredictor:\n",
    "    \n",
    "    \"\"\" Feature predictor for a normally distributed real-valued, continuous feature.\n",
    "\n",
    "        attr:\n",
    "            k : int -- number of classes\n",
    "            mu : np.ndarray[k] -- vector containing per class mean of the feature\n",
    "            sigma : np.ndarray[k] -- vector containing per class std. deviation of the feature\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        \"\"\" constructor\n",
    "\n",
    "        args : k -- number of classes\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.mu = np.zeros(k)\n",
    "        self.sigma = np.zeros(k)\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"update predictor statistics (mu, sigma) for Gaussian distribution\n",
    "\n",
    "        args:\n",
    "            x : pd.Series -- feature values\n",
    "            y : np.Series -- class labels\n",
    "            \n",
    "        return : GaussianPredictor -- return self for convenience\n",
    "        \n",
    "        \"\"\"\n",
    "        # df = pd.DataFrame({\"values\":x,\"labels\":y})\n",
    "        # groups = df.groupby(\"labels\")\n",
    "        # self.mu = np.array((groups.mean()))\n",
    "        # self.sigma = np.sqrt(np.array(groups.var(ddof=0)))\n",
    "        y=np.array(y)\n",
    "        x=np.array(x)\n",
    "        \n",
    "        \n",
    "        for i in range(self.k):\n",
    "            ybools = (y==i)\n",
    "            # given_i = np.array([x[j] for j in range(len(y)) if y[j] == i])\n",
    "            given_i = np.extract(ybools,x)\n",
    "            self.mu[i]=given_i.mean()\n",
    "            self.sigma[i]=np.sqrt(given_i.var())\n",
    "        return self\n",
    "            \n",
    "    def partial_log_likelihood(self, x):\n",
    "        \"\"\" log likelihood of feature values x according to each class\n",
    "\n",
    "        args:\n",
    "            x : pd.Series -- feature values\n",
    "\n",
    "        return: np.ndarray[self.k, len(x)] : log likelihood for this feature for each class\n",
    "        \"\"\"\n",
    "        logpdfs = np.zeros((self.k,len(x)))\n",
    "        for i in range(self.k):\n",
    "            logpdfs[i]=stats.norm(loc=self.mu[i],scale=self.sigma[i]).logpdf(x)\n",
    "        return logpdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class CategoricalPredictor:\n",
    "    \"\"\" Feature predictor for a categorical feature.\n",
    "\n",
    "        attr: \n",
    "            k : int -- number of classes\n",
    "            p : Dict[feature_value, np.ndarray[k]] -- dictionary of vectors containing per-class probability of a feature value;\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        \"\"\" constructor\n",
    "\n",
    "        args : k -- number of classes\n",
    "        \"\"\"\n",
    "        self.k=k\n",
    "\n",
    "    def fit(self, x, y, alpha=1.):\n",
    "        \"\"\" initializes the predictor statistics (p) for Categorical distribution\n",
    "        \n",
    "        args:\n",
    "            x : pd.Series -- feature values\n",
    "            y : pd.Series -- class labels\n",
    "        \n",
    "        kwargs:\n",
    "            alpha : float -- smoothing factor\n",
    "\n",
    "        return : CategoricalPredictor -- returns self for convenience:\n",
    "        \"\"\"\n",
    "        y=np.array(y)\n",
    "        x=np.array(x)\n",
    "        self.p = {}\n",
    "        for char in set(x):\n",
    "#             print(self.k)\n",
    "#             print(char)\n",
    "#             print(self.p)\n",
    "            self.p[char]=np.zeros(self.k)\n",
    "            \n",
    "        \n",
    "        for i in range(self.k):\n",
    "            # n=sum([1 for j in range(len(y)) if y[j] == i])\n",
    "            ybools= (y==i)\n",
    "            \n",
    "            n=np.sum( ybools )\n",
    "            for char in set(x):\n",
    "                xbools= (x == char)\n",
    "                # nj=sum([1 for j in range(len(y)) if x[j] == char and y[j] == i ])\n",
    "                nj = np.sum(np.logical_and(xbools,ybools))\n",
    "                (self.p[char])[i] = (nj + alpha)/ (n+len(set(x))*alpha)\n",
    "        return self\n",
    "\n",
    "    def partial_log_likelihood(self, x):\n",
    "        \"\"\" log likelihood of feature values x according to each class\n",
    "\n",
    "        args:\n",
    "            x : pd.Series -- vector of feature values\n",
    "\n",
    "        return : np.ndarray[self.k, len(x)] -- matrix of log likelihood for this feature\n",
    "        \"\"\"\n",
    "        like = np.zeros((self.k,len(x)))\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            for j,char in enumerate(x):\n",
    "                like[i][j]=np.log(self.p[char][i])\n",
    "        return like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, df_feature, df_label, alpha=1.):\n",
    "        self.predictor = {}\n",
    "        self.l = df_label.value_counts()\n",
    "        self.unique_label = len(df_label.unique())\n",
    "        self.log_prior = np.zeros(self.unique_label)\n",
    "        n = len(df_label)\n",
    "        # Initialize log_prior\n",
    "        for i in range(self.unique_label):\n",
    "            ybools= (label==i)\n",
    "            nt=np.sum( ybools )\n",
    "            self.log_prior[i] = np.log( (nt+alpha)/(n+(self.unique_label*alpha)))\n",
    "            \n",
    "        # Initialize predictor\n",
    "        for col in df_feature.columns:\n",
    "            if df_feature[col].dtype == 'object':\n",
    "#                 print(df_feature[col].shape)\n",
    "#                 print(df_feature[col].values.reshape(-1,1))\n",
    "#                 self.predictor[col] = CategoricalPredictor(self.unique_label).fit(df_feature[col], df_label)\n",
    "                self.predictor[col] = MultinomialNB().fit(df_feature[col].values.reshape(-1,1), df_label)\n",
    "            elif df_feature[col].dtype == 'int64':\n",
    "#                 self.predictor[col] = GaussianPredictor(self.unique_label).fit(df_feature[col], df_label)\n",
    "                self.predictor[col] = GaussianNB().fit(df_feature[col].values.reshape(-1,1), df_label)\n",
    "        \n",
    "    def log_likelihood(self, df_feature):\n",
    "        likelihood = np.array(([self.log_prior,]*len(df_feature))).transpose()\n",
    "        for col in self.predictor:\n",
    "            model = self.predictor[col]\n",
    "#             print(df_feature[col].values.reshape(-1,1))\n",
    "#             print(model.predict_log_proba(df_feature[col].values.reshape(-1,1)))\n",
    "            likelihood += model.predict_log_proba(df_feature[col].values.reshape(-1,1)).T\n",
    "#             likelihood += model.partial_log_likelihood(df_feature[col])\n",
    "            print(likelihood)\n",
    "        return likelihood \n",
    "        \n",
    "    def predict(self, df_feature):\n",
    "        pred = np.argmax(self.log_likelihood(df_feature),axis = 0)\n",
    "        return pred\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Static Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10.85790818 -10.85790818 -10.85790818 ... -10.85790818 -10.85790818\n",
      "  -10.85790818]\n",
      " [-15.77782828 -15.77782828 -15.77782828 ... -15.77782828 -15.77782828\n",
      "  -15.77782828]\n",
      " [-14.5274491  -14.5274491  -14.5274491  ... -14.5274491  -14.5274491\n",
      "  -14.5274491 ]\n",
      " ...\n",
      " [-11.95664214 -11.95664214 -11.95664214 ... -11.95664214 -11.95664214\n",
      "  -11.95664214]\n",
      " [-12.37635316 -12.37635316 -12.37635316 ... -12.37635316 -12.37635316\n",
      "  -12.37635316]\n",
      " [-13.72584358 -13.72584358 -13.72584358 ... -13.72584358 -13.72584358\n",
      "  -13.72584358]]\n",
      "[[-11.43303658 -11.43303658 -11.43303658 ... -11.43303658 -11.43303658\n",
      "  -11.43303658]\n",
      " [-21.27287677 -21.27287677 -21.27287677 ... -21.27287677 -21.27287677\n",
      "  -21.27287677]\n",
      " [-18.77211842 -18.77211842 -18.77211842 ... -18.77211842 -18.77211842\n",
      "  -18.77211842]\n",
      " ...\n",
      " [-13.6305045  -13.6305045  -13.6305045  ... -13.6305045  -13.6305045\n",
      "  -13.6305045 ]\n",
      " [-14.46992653 -14.46992653 -14.46992653 ... -14.46992653 -14.46992653\n",
      "  -14.46992653]\n",
      " [-17.16890738 -17.16890738 -17.16890738 ... -17.16890738 -17.16890738\n",
      "  -17.16890738]]\n",
      "[[-12.00816498 -12.00816498 -12.00816498 ... -12.00816498 -12.00816498\n",
      "  -12.00816498]\n",
      " [-26.76792527 -26.76792527 -26.76792527 ... -26.76792527 -26.76792527\n",
      "  -26.76792527]\n",
      " [-23.01678774 -23.01678774 -23.01678774 ... -23.01678774 -23.01678774\n",
      "  -23.01678774]\n",
      " ...\n",
      " [-15.30436685 -15.30436685 -15.30436685 ... -15.30436685 -15.30436685\n",
      "  -15.30436685]\n",
      " [-16.56349991 -16.56349991 -16.56349991 ... -16.56349991 -16.56349991\n",
      "  -16.56349991]\n",
      " [-20.61197118 -20.61197118 -20.61197118 ... -20.61197118 -20.61197118\n",
      "  -20.61197118]]\n",
      "[[-12.60470746 -12.59831342 -12.58357379 ... -12.60545039 -12.60016816\n",
      "  -12.59643363]\n",
      " [-32.48213311 -32.42572273 -32.30604159 ... -32.48536139 -32.45389019\n",
      "  -32.42893739]\n",
      " [-27.35861856 -27.30007485 -27.21545828 ... -27.35536274 -27.35242997\n",
      "  -27.34304741]\n",
      " ...\n",
      " [-16.92700702 -16.9393657  -16.97030022 ... -16.9257634  -16.93504643\n",
      "  -16.94190407]\n",
      " [-18.56686554 -18.61750242 -18.69781011 ... -18.56887652 -18.57499733\n",
      "  -18.58520194]\n",
      " [-24.3581457  -24.3404516  -24.23159496 ... -24.37118477 -24.30717986\n",
      "  -24.26931494]]\n",
      "[[-13.20694434 -13.19840222 -13.18581067 ... -13.20768727 -13.183523\n",
      "  -13.14843272]\n",
      " [-38.26951275 -37.8874998  -38.09342123 ... -38.27274103 -38.44597614\n",
      "  -38.65449667]\n",
      " [-31.52752188 -31.40458206 -31.3843616  ... -31.52426606 -31.63524701\n",
      "  -31.79508562]\n",
      " ...\n",
      " [-18.7153317  -18.64730418 -18.7586249  ... -18.71408809 -18.74405245\n",
      "  -18.75941392]\n",
      " [-20.52508057 -20.59691624 -20.65602514 ... -20.52709155 -20.58847741\n",
      "  -20.69868704]\n",
      " [-27.37663951 -27.68171488 -27.25008877 ... -27.38967858 -27.29549333\n",
      "  -27.315748  ]]\n",
      "[[-13.78207274 -13.77353062 -13.76093907 ... -13.78281567 -13.7586514\n",
      "  -13.72356112]\n",
      " [-43.76456125 -43.38254829 -43.58846972 ... -43.76778952 -43.94102463\n",
      "  -44.14954516]\n",
      " [-35.7721912  -35.64925138 -35.62903092 ... -35.76893538 -35.87991633\n",
      "  -36.03975494]\n",
      " ...\n",
      " [-20.38919406 -20.32116654 -20.43248725 ... -20.38795044 -20.4179148\n",
      "  -20.43327628]\n",
      " [-22.61865394 -22.69048962 -22.74959852 ... -22.62066492 -22.68205078\n",
      "  -22.79226042]\n",
      " [-30.81970331 -31.12477868 -30.69315257 ... -30.83274238 -30.73855712\n",
      "  -30.7588118 ]]\n",
      "Counter({0: 14392})\n",
      "Counter({0: 8121, 4: 2625, 8: 1778, 3: 1155, 9: 478, 2: 172, 1: 63})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "classifier = NaiveBayesClassifier(sseverity_X_train, sseverity_y_train)\n",
    "predict = classifier.predict(sseverity_X_test)\n",
    "c = collections.Counter(predict)\n",
    "d = collections.Counter(sseverity_y_test)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Severity Prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
